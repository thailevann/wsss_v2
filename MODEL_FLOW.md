# Model Architecture Flow

TÃ i liá»‡u nÃ y mÃ´ táº£ chi tiáº¿t luá»“ng xá»­ lÃ½ cá»§a model BCSS-WSSS vá»›i CONCH backbone.

## Tá»•ng quan

Model sá»­ dá»¥ng CONCH (Contrastive learning for histopathology) lÃ m backbone, káº¿t há»£p vá»›i Expert Prompt Bank, Knowledge Bank (BERT), vÃ  Multi-scale Similarity Head.

---

## ğŸ”¹ FORWARD PASS FLOW

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PROTOTYPE GENERATION (Pre-training, Optional)              â”‚
â”‚                                                              â”‚
â”‚  Input:                                                      â”‚
â”‚  â€¢ Training images (only single-label, 1 class per image)   â”‚
â”‚  â€¢ Label CSV                                                 â”‚
â”‚                                                              â”‚
â”‚  Process:                                                    â”‚
â”‚  1) Filter images:                                          â”‚
â”‚     â€¢ Keep only images with exactly 1 class                 â”‚
â”‚     â€¢ Skip multi-label images                                â”‚
â”‚                                                              â”‚
â”‚  2) Extract features:                                        â”‚
â”‚     â€¢ Load CONCH vision encoder                              â”‚
â”‚     â€¢ For each image:                                        â”‚
â”‚       - Resize to 448Ã—448                                    â”‚
â”‚       - Extract features via encode_image()                  â”‚
â”‚       - Normalize                                            â”‚
â”‚     â€¢ Group by class                                         â”‚
â”‚                                                              â”‚
â”‚  3) K-means clustering:                                     â”‚
â”‚     â€¢ For each class:                                        â”‚
â”‚       - Cosine similarity K-means                           â”‚
â”‚       - k clusters per class (from k_list)                  â”‚
â”‚       - Get cluster centers                                  â”‚
â”‚                                                              â”‚
â”‚  4) Save prototypes:                                         â”‚
â”‚     â€¢ Concatenate all cluster centers                       â”‚
â”‚     â€¢ Shape: [P, D_proto] where P = sum(k_list)              â”‚
â”‚     â€¢ Save to .pkl file                                      â”‚
â”‚                                                              â”‚
â”‚  Output:                                                     â”‚
â”‚  â€¢ Image Prototypes [P, D_proto]                            â”‚
â”‚    (Loaded into model as buffer)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚  (Prototypes loaded once)
                            â”‚
                            â–¼
[Input Image] I [B, 3, 448, 448]
        â”‚
        â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  CONCH Vision        â”‚   (ViT-B/16)
 â”‚  Backbone            â”‚
 â”‚                      â”‚
 â”‚  Forward Pass:       â”‚
 â”‚  â€¢ Hook táº¡i block 2  â”‚ â†’ P1 [B,768,H1,W1] --> khÃ´ng dÃ¹ng 
 â”‚  â€¢ Hook táº¡i block 5  â”‚ â†’ P2 [B,768,H2,W2] 
 â”‚  â€¢ Hook táº¡i block 8  â”‚ â†’ P3 [B,768,H3,W3] 
 â”‚  â€¢ Hook táº¡i block 11 â”‚ â†’ P4 [B,768,H4,W4] 
 â”‚                      â”‚
 â”‚  â€¢ Train: last_k=2   â”‚
 â”‚  â€¢ Frozen: others    â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚  Táº¥t cáº£ Ä‘Æ°á»£c extract song song tá»« hooks
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚              â”‚              â”‚
        â–¼              â–¼              â–¼              â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  P2 Features â”‚ â”‚  P3 Features â”‚ â”‚  P4 Features â”‚
 â”‚  [B,768,H2,W2]â”‚ â”‚  [B,768,H3,W3]â”‚ â”‚  [B,768,H4,W4]â”‚
 â”‚  (block 5)   â”‚ â”‚  (block 8)   â”‚ â”‚  (block 11)  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚              â”‚
        â”‚              â”‚              â”‚  Flatten to Tokens
        â”‚              â”‚              â–¼
        â”‚              â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚      â”‚  P4 Tokens            â”‚
        â”‚              â”‚      â”‚  [B, N, 768]          â”‚
        â”‚              â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚              â”‚
        â”‚              â”‚              â”‚
        â”‚              â”‚              â”‚  (cháº¡y song song)
        â”‚              â”‚              â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                                   â”‚
        â–¼                                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Knowledge Bank      â”‚                    â”‚  Expert Prompt Bank  â”‚
â”‚  (BERT)              â”‚                    â”‚                      â”‚
â”‚                      â”‚                    â”‚  â€¢ Coarse Prompts   â”‚
â”‚  Input:              â”‚                    â”‚    (WITH grad)       â”‚
â”‚  â€¢ Class names       â”‚                    â”‚  â€¢ Fine Prompts     â”‚
â”‚  â€¢ Knowledge texts   â”‚                    â”‚    (NO grad, cached) â”‚
â”‚  (khÃ´ng phá»¥ thuá»™c P4)â”‚                    â”‚  (khÃ´ng phá»¥ thuá»™c P4)â”‚
â”‚                      â”‚                    â”‚                      â”‚
â”‚  Process:            â”‚                    â”‚  Process:           â”‚
â”‚  â€¢ BERT encode       â”‚                    â”‚  â€¢ Generate prompts  â”‚
â”‚  â€¢ CLS token         â”‚                    â”‚  â€¢ Purification      â”‚
â”‚    [K, bert_dim]     â”‚                    â”‚  â€¢ Tokenize          â”‚
â”‚  â€¢ Project to:       â”‚                    â”‚  â€¢ Encode (LoRA)     â”‚
â”‚    - proj_to_vision: â”‚                    â”‚                      â”‚
â”‚      Linear(bert_dimâ”‚                    â”‚  Output:            â”‚
â”‚      â†’ 768)          â”‚                    â”‚  â€¢ Coarse [K,512]    â”‚
â”‚      â†’ [K,768]       â”‚                    â”‚  â€¢ Fine [Nf,512]     â”‚
â”‚    - proj_to_text:   â”‚                    â”‚  â€¢ idx_by_class      â”‚
â”‚      Linear(bert_dimâ”‚                    â”‚                      â”‚
â”‚      â†’ 512)           â”‚                    â”‚                      â”‚
â”‚      â†’ [K,512]       â”‚                    â”‚                      â”‚
â”‚                      â”‚                    â”‚                      â”‚
â”‚  Output:             â”‚                    â”‚                      â”‚
â”‚  â€¢ Know_tok [K,768]  â”‚                    â”‚                      â”‚
â”‚  â€¢ Know_text [K,512] â”‚                    â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                       â”‚
        â”‚  (Knowledge Tokens)                    â”‚  (Text Embeddings)
        â”‚                                       â”‚
        â”‚                                       â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚                                       â”‚
        â”‚                                       â”‚
        â–¼                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Knowledge Attention (2 layers)                        â”‚
â”‚                                                          â”‚
â”‚  Input:                                                  â”‚
â”‚  â€¢ P4 Tokens [B, N, 768]  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â€¢ Knowledge Tokens [K, 768] â†’ expand to [B, K, 768] â”€â”€â”˜ â”‚
â”‚                                                          â”‚
â”‚  Layer 1:                                                â”‚
â”‚  â€¢ Concat: [B, N+K, 768]                                 â”‚
â”‚  â€¢ LayerNorm1                                            â”‚
â”‚  â€¢ Multi-head Self-Attention                             â”‚
â”‚  â€¢ Residual: x = x + attn_out                           â”‚
â”‚  â€¢ LayerNorm2                                             â”‚
â”‚  â€¢ MLP:                                                  â”‚
â”‚    - Linear(768 â†’ 3072) [hidden = dimÃ—4]                â”‚
â”‚    - GELU                                                â”‚
â”‚    - Dropout                                             â”‚
â”‚    - Linear(3072 â†’ 768)                                  â”‚
â”‚    - Dropout                                              â”‚
â”‚  â€¢ Residual: x = x + mlp_out                             â”‚
â”‚                                                          â”‚
â”‚  Layer 2:                                                â”‚
â”‚  â€¢ Same structure as Layer 1                             â”‚
â”‚                                                          â”‚
â”‚  â€¢ Extract image tokens: [B, N, 768]                     â”‚
â”‚                                                          â”‚
â”‚  Output:                                                 â”‚
â”‚  â€¢ Enhanced P4 [B, 768, H4, W4]                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚  Enhanced P4
                            â”‚
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                       â”‚
        â”‚  (Text embeddings tá»« Prompt Bank      â”‚  (Vision features)
        â”‚   vÃ  Knowledge Bank)                  â”‚
        â”‚                                       â”‚
        â–¼                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Base Text Fusion    â”‚            â”‚  Base Similarity      â”‚
â”‚                      â”‚            â”‚  Computation         â”‚
â”‚  Input:              â”‚            â”‚                      â”‚
â”‚  â€¢ Coarse [K,512]    â”‚            â”‚  Input:               â”‚
â”‚    (tá»« Prompt Bank)  â”‚            â”‚  â€¢ Base [K,512]        â”‚
â”‚  â€¢ Know_text [K,512] â”‚            â”‚    (tá»« Text Fusion)   â”‚
â”‚    (tá»« Knowledge Bank)â”‚            â”‚  â€¢ P2, P3, Enhanced P4â”‚
â”‚                      â”‚            â”‚                      â”‚
â”‚  Process:            â”‚            â”‚  Process:             â”‚
â”‚  â€¢ base = coarse +   â”‚            â”‚  For each scale:      â”‚
â”‚    Î± Ã— know_text     â”‚            â”‚  â€¢ to_w2: Linear(512â†’768)â”‚
â”‚  â€¢ Normalize         â”‚            â”‚    + LayerNorm        â”‚
â”‚                      â”‚            â”‚  â€¢ to_w3: Linear(512â†’768)â”‚
â”‚  Output:             â”‚            â”‚    + LayerNorm        â”‚
â”‚  â€¢ Base [K,512] â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚  â€¢ to_w4: Linear(512â†’768)â”‚
â”‚                      â”‚            â”‚    + LayerNorm        â”‚
â”‚                      â”‚            â”‚  â€¢ Normalize text & visionâ”‚
â”‚                      â”‚            â”‚  â€¢ Compute similarity  â”‚
â”‚                      â”‚            â”‚  â€¢ Apply logit_scale  â”‚
â”‚                      â”‚            â”‚  â€¢ GAP â†’ logits        â”‚
â”‚                      â”‚            â”‚                      â”‚
â”‚                      â”‚            â”‚  Output:              â”‚
â”‚                      â”‚            â”‚  â€¢ l2, l3, l4 [B,K]  â”‚
â”‚                      â”‚            â”‚  â€¢ prob_base [B,K]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Image-conditioned   â”‚
                    â”‚  Fine Selection      â”‚
                    â”‚                      â”‚
                    â”‚  Input:              â”‚
                    â”‚  â€¢ P4 Enhanced       â”‚
                    â”‚  â€¢ Fine Cache [Nf,512]â”‚
                    â”‚                      â”‚
                    â”‚  Process:            â”‚
                    â”‚  â€¢ Pool P4 â†’ [B,768] â”‚
                    â”‚  â€¢ img_to_text:      â”‚
                    â”‚    Linear(768â†’512)   â”‚
                    â”‚    + LayerNorm       â”‚
                    â”‚    â†’ [B,512]         â”‚
                    â”‚  â€¢ Normalize         â”‚
                    â”‚  â€¢ For each class:    â”‚
                    â”‚    - Select fine     â”‚
                    â”‚      embeddings      â”‚
                    â”‚      from idx_by_classâ”‚
                    â”‚    - Compute sim     â”‚
                    â”‚      [B, M]          â”‚
                    â”‚    - Top-K (k=6)     â”‚
                    â”‚    - Weighted mix    â”‚
                    â”‚      (temp=10.0)     â”‚
                    â”‚    - Attr logit:     â”‚
                    â”‚      top1Ã—scale +     â”‚
                    â”‚      marginÃ—sharp    â”‚
                    â”‚                      â”‚
                    â”‚  Output:             â”‚
                    â”‚  â€¢ Fine_vec [B,K,512]â”‚
                    â”‚  â€¢ Attr_logits [B,K] â”‚
                    â”‚  â€¢ Attr_conf [B,K]   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                       â”‚
        â–¼                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Gating Function     â”‚            â”‚  Text Final Fusion    â”‚
â”‚                      â”‚            â”‚                      â”‚
â”‚  Input:              â”‚            â”‚  Input:              â”‚
â”‚  â€¢ Attr_conf [B,K]   â”‚            â”‚  â€¢ Base [K,512]      â”‚
â”‚  â€¢ prob_base [B,K]   â”‚            â”‚  â€¢ Fine_vec [B,K,512] â”‚
â”‚                      â”‚            â”‚  â€¢ Gate [B,K]        â”‚
â”‚  Mode: conf_prob     â”‚            â”‚  â€¢ Beta [K]          â”‚
â”‚  â€¢ g1 = attr_conf    â”‚            â”‚                      â”‚
â”‚  â€¢ g2 = sigmoid(     â”‚            â”‚  Process:             â”‚
â”‚      (prob-Ï„)Ã—sharp) â”‚            â”‚  â€¢ text_final = base +â”‚
â”‚  â€¢ gate = g1 Ã— g2    â”‚            â”‚    Î² Ã— gate Ã— fine   â”‚
â”‚  â€¢ gate = gate^pow    â”‚            â”‚  â€¢ Normalize         â”‚
â”‚                      â”‚            â”‚                      â”‚
â”‚  Output:             â”‚            â”‚  Output:             â”‚
â”‚  â€¢ Gate [B,K]       â”‚            â”‚  â€¢ Text_final        â”‚
â”‚                      â”‚            â”‚    [B,K,512]         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚
                            â”‚
                            â”‚  Text_final [B,K,512]
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Prototype Fusion    â”‚
                    â”‚  (Optional)          â”‚
                    â”‚                      â”‚
                    â”‚  Input:              â”‚
                    â”‚  â€¢ Text_final        â”‚
                    â”‚    [B,K,512]         â”‚
                    â”‚  â€¢ Image Prototypes  â”‚
                    â”‚    [P, D_proto]      â”‚
                    â”‚                      â”‚
                    â”‚  Process:            â”‚
                    â”‚  â€¢ proto_proj:       â”‚
                    â”‚    Linear(D_protoâ†’512)â”‚
                    â”‚    â†’ [P, 512]        â”‚
                    â”‚  â€¢ Normalize         â”‚
                    â”‚  â€¢ Pool per class:   â”‚
                    â”‚    mean([P/K, 512])  â”‚
                    â”‚    â†’ [K, 512]        â”‚
                    â”‚  â€¢ Î±_proto = sigmoid â”‚
                    â”‚    (proto_balance)   â”‚
                    â”‚  â€¢ text_final =      â”‚
                    â”‚    Î±_proto Ã— text +  â”‚
                    â”‚    (1-Î±_proto) Ã—     â”‚
                    â”‚    proto_pooled      â”‚
                    â”‚  â€¢ Normalize         â”‚
                    â”‚                      â”‚
                    â”‚  Output:             â”‚
                    â”‚  â€¢ Text_final        â”‚
                    â”‚    [B,K,512]         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Final Multi-scale  â”‚
                    â”‚  Similarity         â”‚
                    â”‚                      â”‚
                    â”‚  Input:             â”‚
                    â”‚  â€¢ Text_final        â”‚
                    â”‚    [B,K,512]         â”‚
                    â”‚  â€¢ P2, P3, P4        â”‚
                    â”‚                      â”‚
                    â”‚  Process:            â”‚
                    â”‚  â€¢ Multi-scale SIM  â”‚
                    â”‚  â€¢ Similarity maps   â”‚
                    â”‚  â€¢ GAP â†’ logits     â”‚
                    â”‚                      â”‚
                    â”‚  Output:             â”‚
                    â”‚  â€¢ l2, l3, l4 [B,K] â”‚
                    â”‚  â€¢ cam2, cam3, cam4  â”‚
                    â”‚    [B,K,H,W]        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                       â”‚
        â–¼                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CAM Fusion          â”‚            â”‚  Logit Fusion         â”‚
â”‚                      â”‚            â”‚                      â”‚
â”‚  Input:              â”‚            â”‚  Input:              â”‚
â”‚  â€¢ cam2, cam3, cam4  â”‚            â”‚  â€¢ l2, l3, l4 [B,K]  â”‚
â”‚                      â”‚            â”‚                      â”‚
â”‚  Process:            â”‚            â”‚  Process:             â”‚
â”‚  â€¢ Upsample cam3,4   â”‚            â”‚  â€¢ Weighted average   â”‚
â”‚    to cam2 size      â”‚            â”‚  â€¢ w2=0.5, w3=0.75,  â”‚
â”‚  â€¢ Fused = (0.2Ã—cam2 â”‚            â”‚    w4=1.0            â”‚
â”‚    + 0.5Ã—cam3_up     â”‚            â”‚                      â”‚
â”‚    + 1.3Ã—cam4_up)/2.0â”‚            â”‚  Output:             â”‚
â”‚                      â”‚            â”‚  â€¢ Fused_logits      â”‚
â”‚  Output:             â”‚            â”‚    [B,K]            â”‚
â”‚  â€¢ Fused_cam         â”‚            â”‚                      â”‚
â”‚    [B,K,H2,W2]       â”‚            â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Affinity Features   â”‚
                    â”‚                      â”‚
                    â”‚  Input:              â”‚
                    â”‚  â€¢ P2 [B,768,H2,W2]  â”‚
                    â”‚                      â”‚
                    â”‚  Process:            â”‚
                    â”‚  â€¢ aff_proj:         â”‚
                    â”‚    Conv2d(768â†’64,    â”‚
                    â”‚     kernel=1Ã—1)      â”‚
                    â”‚    + GroupNorm(8)    â”‚
                    â”‚    + ReLU            â”‚
                    â”‚                      â”‚
                    â”‚  Output:             â”‚
                    â”‚  â€¢ Aff_feat          â”‚
                    â”‚    [B,64,H2,W2]      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  OUTPUT              â”‚
                    â”‚                      â”‚
                    â”‚  â€¢ Fused_logits      â”‚
                    â”‚    [B, K]            â”‚
                    â”‚  â€¢ Fused_cam         â”‚
                    â”‚    [B, K, H, W]      â”‚
                    â”‚  â€¢ Multi-scale       â”‚
                    â”‚    logits & CAMs     â”‚
                    â”‚  â€¢ Affinity features â”‚
                    â”‚  â€¢ Extras:           â”‚
                    â”‚    - attr_logits     â”‚
                    â”‚    - attr_conf       â”‚
                    â”‚    - gate            â”‚
                    â”‚    - prob_base       â”‚
                    â”‚    - has_fine        â”‚
                    â”‚    - alpha_proto     â”‚
                    â”‚    - feat_aff        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¹ COMPONENT DETAILS

### 1. CONCH Vision Backbone

```
Input: [B, 3, 448, 448]
    â†“
CONCH Visual Encoder (ViT-B/16)
    â†“
Forward Hooks táº¡i blocks [2, 5, 8, 11]
    â†“
P1 [B, 768, H1, W1]  (block 2)  - khÃ´ng dÃ¹ng
P2 [B, 768, H2, W2]  (block 5)  â† Sá»­ dá»¥ng
P3 [B, 768, H3, W3]  (block 8)  â† Sá»­ dá»¥ng
P4 [B, 768, H4, W4]  (block 11) â† Sá»­ dá»¥ng
```

**Trainability**: Chá»‰ train last_k blocks (máº·c Ä‘á»‹nh: 2 blocks cuá»‘i)

### 2. Knowledge Bank (BERT)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Knowledge Bank                      â”‚
â”‚                                      â”‚
â”‚  Input:                              â”‚
â”‚  â€¢ Class names [K]                   â”‚
â”‚  â€¢ Knowledge texts (dict)            â”‚
â”‚                                      â”‚
â”‚  Process:                            â”‚
â”‚  â€¢ BERT Tokenizer                    â”‚
â”‚  â€¢ BERT Encoder (frozen)             â”‚
â”‚  â€¢ Extract CLS token [K, bert_dim]   â”‚
â”‚  â€¢ Projection layers:                â”‚
â”‚    - proj_to_vision:                 â”‚
â”‚      Linear(bert_dim â†’ 768)          â”‚
â”‚      â†’ [K, 768]                      â”‚
â”‚    - proj_to_text:                   â”‚
â”‚      Linear(bert_dim â†’ 512)          â”‚
â”‚      â†’ [K, 512]                      â”‚
â”‚                                      â”‚
â”‚  Output:                             â”‚
â”‚  â€¢ know_vec_bert [K, bert_dim]       â”‚
â”‚  â€¢ know_tok [K, 768] (vision)        â”‚
â”‚  â€¢ know_text [K, 512] (text)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Trainability**: BERT frozen, chá»‰ train projection layers (proj_to_vision, proj_to_text)

### 3. Expert Prompt Bank

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Expert Prompt Bank                  â”‚
â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Coarse Prompts (WITH grad)     â”‚ â”‚
â”‚  â”‚                                â”‚ â”‚
â”‚  â”‚ â€¢ Class Ã— Templates            â”‚ â”‚
â”‚  â”‚ â€¢ Tokenize                      â”‚ â”‚
â”‚  â”‚ â€¢ CONCH encode (LoRA)          â”‚ â”‚
â”‚  â”‚ â€¢ Average per class             â”‚ â”‚
â”‚  â”‚                                â”‚ â”‚
â”‚  â”‚ Output: [K, 512]               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Fine Prompts (NO grad, cached) â”‚ â”‚
â”‚  â”‚                                â”‚ â”‚
â”‚  â”‚ â€¢ Generate combinations:       â”‚ â”‚
â”‚  â”‚   - Structure Ã— Color          â”‚ â”‚
â”‚  â”‚   - Structure only             â”‚ â”‚
â”‚  â”‚ â€¢ Purification:                â”‚ â”‚
â”‚  â”‚   - Ambiguity filter           â”‚ â”‚
â”‚  â”‚   - Redundancy removal         â”‚ â”‚
â”‚  â”‚ â€¢ Tokenize                      â”‚ â”‚
â”‚  â”‚ â€¢ CONCH encode (no_grad)       â”‚ â”‚
â”‚  â”‚ â€¢ Cache [Nf, 512]              â”‚ â”‚
â”‚  â”‚                                â”‚ â”‚
â”‚  â”‚ Refresh: má»—i epoch              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. Image-conditioned Fine Selection

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fine Prompt Selection               â”‚
â”‚                                      â”‚
â”‚  Input:                              â”‚
â”‚  â€¢ P4 Enhanced [B,768,H4,W4]         â”‚
â”‚  â€¢ Fine cache [Nf, 512]              â”‚
â”‚  â€¢ idx_by_class (list)               â”‚
â”‚                                      â”‚
â”‚  Process:                            â”‚
â”‚  â€¢ Pool P4 â†’ [B, 768]                â”‚
â”‚  â€¢ img_to_text projection:           â”‚
â”‚    Linear(768 â†’ 512)                 â”‚
â”‚    + LayerNorm                       â”‚
â”‚    â†’ [B, 512]                        â”‚
â”‚  â€¢ Normalize                         â”‚
â”‚                                      â”‚
â”‚  For each class c:                   â”‚
â”‚    â€¢ Select fine embeddings [M,512]  â”‚
â”‚    â€¢ Compute similarity [B, M]        â”‚
â”‚    â€¢ Top-K selection (k=6)           â”‚
â”‚    â€¢ Weighted mixture:                â”‚
â”‚      w = softmax(sim Ã— temp=10.0)    â”‚
â”‚      vec = Î£ w_i Ã— emb_i             â”‚
â”‚    â€¢ Attribute confidence:            â”‚
â”‚      conf = sigmoid(top1 + margin)   â”‚
â”‚                                      â”‚
â”‚  Output:                             â”‚
â”‚  â€¢ Fine_vec [B, K, 512]              â”‚
â”‚  â€¢ Attr_logits [B, K]                â”‚
â”‚  â€¢ Attr_conf [B, K]                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. Confidence-gated Fusion

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Gating Mechanism                    â”‚
â”‚                                      â”‚
â”‚  Mode: conf_prob                     â”‚
â”‚                                      â”‚
â”‚  â€¢ g1 = attr_conf [B, K]            â”‚
â”‚  â€¢ g2 = sigmoid((prob_base - Ï„)     â”‚
â”‚              Ã— sharpness)            â”‚
â”‚  â€¢ gate = g1 Ã— g2                   â”‚
â”‚  â€¢ gate = gate^pow                  â”‚
â”‚                                      â”‚
â”‚  Text Final:                         â”‚
â”‚  â€¢ base [B, K, 512]                  â”‚
â”‚  â€¢ + Î² [K] Ã— gate [B,K,1]            â”‚
â”‚      Ã— fine [B,K,512]                â”‚
â”‚  â€¢ Normalize                         â”‚
â”‚                                      â”‚
â”‚  Output:                             â”‚
â”‚  â€¢ Text_final [B, K, 512]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6. Multi-scale Similarity Head

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Multi-scale SIM Head                 â”‚
â”‚                                      â”‚
â”‚  Input:                              â”‚
â”‚  â€¢ Text [K,512] or [B,K,512]        â”‚
â”‚  â€¢ Vision features P2, P3, P4        â”‚
â”‚                                      â”‚
â”‚  Projection layers:                  â”‚
â”‚  â€¢ to_w2: Linear(512â†’768) + LayerNormâ”‚
â”‚  â€¢ to_w3: Linear(512â†’768) + LayerNormâ”‚
â”‚  â€¢ to_w4: Linear(512â†’768) + LayerNormâ”‚
â”‚                                      â”‚
â”‚  For each scale (P2, P3, P4):        â”‚
â”‚    â€¢ Project text â†’ vision dim       â”‚
â”‚      using corresponding to_w        â”‚
â”‚    â€¢ Normalize both                  â”‚
â”‚    â€¢ Compute similarity:             â”‚
â”‚      sim = einsum("bchw,kc->bkhw")   â”‚
â”‚    â€¢ Apply logit_scale (learnable)   â”‚
â”‚    â€¢ GAP â†’ logits [B, K]            â”‚
â”‚                                      â”‚
â”‚  Output:                             â”‚
â”‚  â€¢ Logits: l2, l3, l4 [B, K]        â”‚
â”‚  â€¢ CAMs: cam2, cam3, cam4            â”‚
â”‚      [B, K, H, W]                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¹ TRAINING FLOW

```
[Training Batch]
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Forward Pass        â”‚
â”‚  â€¢ Get logits & CAMs â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                               â”‚
        â–¼                                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Multi-scale Loss    â”‚                    â”‚  Equivariance Loss  â”‚
â”‚                      â”‚                    â”‚                      â”‚
â”‚  L_ms = (w2Ã—BCE(l2) +â”‚                    â”‚  L_eq = ||CAM(img) - â”‚
â”‚         w3Ã—BCE(l3) + â”‚                    â”‚         flip(CAM(    â”‚
â”‚         w4Ã—BCE(l4)) /â”‚                    â”‚         flip(img)))|| â”‚
â”‚         (w2+w3+w4)   â”‚                    â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                               â”‚
        â”‚                                               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Attribute Loss      â”‚
                    â”‚  (Optional)          â”‚
                    â”‚                      â”‚
                    â”‚  L_attr = BCE(        â”‚
                    â”‚    attr_logits,      â”‚
                    â”‚    labels)           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Total Loss         â”‚
                    â”‚                      â”‚
                    â”‚  L = L_ms +          â”‚
                    â”‚      Î»Ã—L_eq +        â”‚
                    â”‚      w_attrÃ—L_attr   â”‚
                    â”‚                      â”‚
                    â”‚  Where:             â”‚
                    â”‚  â€¢ Î» = 0.15Ã—min(1,  â”‚
                    â”‚        epoch/3)      â”‚
                    â”‚  â€¢ w_attr = 0.05     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Backward & Update   â”‚
                    â”‚                      â”‚
                    â”‚  â€¢ Vision params     â”‚
                    â”‚    (last_k blocks)   â”‚
                    â”‚  â€¢ LoRA params      â”‚
                    â”‚  â€¢ Head params      â”‚
                    â”‚                      â”‚
                    â”‚  Optimizers:         â”‚
                    â”‚  â€¢ Adam (vision)    â”‚
                    â”‚  â€¢ Adam (head)      â”‚
                    â”‚  â€¢ Adam (lora)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¹ EVALUATION FLOW

```
[Validation/Test Image]
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Forward Pass        â”‚
â”‚  (with TTA)          â”‚
â”‚                      â”‚
â”‚  â€¢ Multiple scales   â”‚
â”‚  â€¢ Horizontal flip   â”‚
â”‚  â€¢ Average results   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                               â”‚
        â–¼                                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Classification Eval  â”‚                    â”‚  Pseudo mIoU Eval     â”‚
â”‚                      â”‚                    â”‚                      â”‚
â”‚  â€¢ Compute metrics:  â”‚                    â”‚  â€¢ CAM â†’ Mask        â”‚
â”‚    - F1 (micro/macro)â”‚                    â”‚  â€¢ Affinity prop      â”‚
â”‚    - AUC-ROC         â”‚                    â”‚  â€¢ Tissue mask        â”‚
â”‚    - mAP             â”‚                    â”‚  â€¢ Compute mIoU       â”‚
â”‚  â€¢ Tune thresholds   â”‚                    â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¹ DIMENSIONALITY SUMMARY

| Component | Shape | Description |
|-----------|-------|-------------|
| Input Image | [B, 3, 448, 448] | RGB image |
| P2 | [B, 768, H2, W2] | Vision feature level 2 (block 5) |
| P3 | [B, 768, H3, W3] | Vision feature level 3 (block 8) |
| P4 | [B, 768, H4, W4] | Vision feature level 4 (block 11) |
| Knowledge Tokens | [K, 768] | BERT knowledge in vision space |
| Knowledge Text | [K, 512] | BERT knowledge in text space |
| Coarse Embeddings | [K, 512] | Coarse prompts per class |
| Fine Embeddings | [Nf, 512] | Cached fine prompts |
| Base Text | [K, 512] | Coarse + Î±Ã—Knowledge |
| Image Text | [B, 512] | Image-conditioned embedding |
| Fine Vectors | [B, K, 512] | Selected fine prompts |
| Text Final | [B, K, 512] | Final text embedding (after gate + beta + optional prototype) |
| Image Prototypes | [P, D_proto] | Prototype features (P = sum of k_list per class) |
| Prototype Pooled | [K, 512] | Per-class mean of prototypes |
| Logits | [B, K] | Classification logits (K=4) |
| CAMs | [B, K, H, W] | Class activation maps |
| Affinity Features | [B, 64, H2, W2] | For pseudo mask generation |

---

## ğŸ”¹ KEY DESIGN CHOICES

### 1. Fine Prompt Caching
- Fine prompts Ä‘Æ°á»£c encode má»™t láº§n (no_grad) vÃ  cache
- Refresh má»—i epoch Ä‘á»ƒ track LoRA updates
- TrÃ¡nh OOM khi training

### 2. Image-conditioned Selection
- Fine prompts Ä‘Æ°á»£c chá»n dá»±a trÃªn image content
- Top-K selection vá»›i temperature-weighted mixture
- Attribute confidence tá»« margin term

### 3. Confidence Gating
- Káº¿t há»£p attribute confidence vÃ  base probability
- Äiá»u khiá»ƒn contribution cá»§a fine prompts
- Mode: conf_prob (g1 Ã— g2)

### 4. Multi-scale Fusion
- Sá»­ dá»¥ng 3 scales (P2, P3, P4)
- Weights: 0.5, 0.75, 1.0 cho logits
- Weights: 0.2, 0.5, 1.3 cho CAMs

### 5. Knowledge Integration
- BERT knowledge vÃ o cáº£ vision space (attention vá»›i MLP)
- VÃ  text space (fusion vá»›i Î±=0.7)
- Knowledge Attention Block: 2 layers, má»—i layer cÃ³ MLP (768â†’3072â†’768)

### 6. LoRA for Text
- Chá»‰ train LoRA parameters trong CONCH text tower
- Efficient fine-tuning cá»§a text encoder

### 7. Image Prototypes (Optional)
- Prototypes Ä‘Æ°á»£c generate tá»« áº£nh training cÃ³ Ä‘Ãºng 1 class (single-label)
- Sá»­ dá»¥ng CONCH vision encoder Ä‘á»ƒ extract features
- K-means clustering per class Ä‘á»ƒ táº¡o cluster centers
- Prototypes Ä‘Æ°á»£c project tá»« vision space sang text space qua `proto_proj`: Linear(D_protoâ†’512)
- Fusion vá»›i text_final: `Î±_proto Ã— text + (1-Î±_proto) Ã— proto`
- Î±_proto lÃ  learnable parameter (sigmoid(proto_balance))

### 8. Projection Layers Summary
- **Knowledge Bank**: proj_to_vision (bert_dimâ†’768), proj_to_text (bert_dimâ†’512)
- **Knowledge Attention**: MLP trong má»—i layer (768â†’3072â†’768 vá»›i GELU)
- **Multi-scale SIM**: to_w2, to_w3, to_w4 (512â†’768 + LayerNorm)
- **Image-conditioned Selection**: img_to_text (768â†’512 + LayerNorm)
- **Prototype Fusion**: proto_proj (D_protoâ†’512)
- **Affinity Features**: aff_proj (Conv2d 768â†’64 + GroupNorm + ReLU)

---

## ğŸ”¹ CLASS NAMES

- **Tumor** (Class 0) - "tumor epithelium"
- **Stroma** (Class 1) - "tumor-associated stroma"
- **Lymphocytic infiltrate** (Class 2) - "lymphocyte infiltrate"
- **Necrosis** (Class 3) - "necrosis"

---

## ğŸ”¹ OUTPUT FORMAT

Model tráº£ vá» trong `forward_cam_logits_multiscale()`:

```python
return (
    fused_logits,      # [B, K] - Classification logits
    fused_cam,         # [B, K, H, W] - Fused CAMs
    (l2, l3, l4),      # Multi-scale logits
    (cam2, cam3, cam4), # Multi-scale CAMs
    extras             # Dictionary:
                       #   - attr_logits [B, K]
                       #   - attr_conf [B, K]
                       #   - gate [B, K]
                       #   - prob_base [B, K]
                       #   - has_fine (bool)
                       #   - alpha_proto (float or None)
                       #   - feat_aff [B, 64, H, W]
)
```
